{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import time\n",
    "from tiki.mini import TikiMini\n",
    "import time \n",
    "tiki = TikiMini()\n",
    "tiki.set_motor_mode(tiki.MOTOR_MODE_PID)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_lane_detection(binary_warped):\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:, :], axis=0)\n",
    "\n",
    "    midpoint = histogram.shape[0] // 2\n",
    "    left_peak = np.argmax(histogram[:midpoint])\n",
    "    right_peak = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "\n",
    "    offset = 30\n",
    "    # print(left_peak, right_peak)\n",
    "    #print(left_peak, right_peak)\n",
    "    if (left_peak < 150 - offset or left_peak > 210 + offset):\n",
    "        left_peak = right_peak - 60\n",
    "    if (right_peak > 210 - offset or right_peak < 210 + offset):\n",
    "        right_peak = left_peak + 60\n",
    "\n",
    "    return left_peak, right_peak\n",
    "\n",
    "def hough_transform(image):\n",
    "    # Grayscale 변환\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Canny 엣지 검출\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, minLineLength=30, maxLineGap=10)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return image, lines\n",
    "\n",
    "def draw_center_line(image, left_lane, right_lane):\n",
    "    # 이미지 크기\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # 왼쪽과 오른쪽 차선의 x 좌표\n",
    "    left_x = left_lane\n",
    "    right_x = right_lane\n",
    "\n",
    "    # 두 차선의 가운데 x 좌표 계산\n",
    "    center_x = (left_x + right_x) // 2\n",
    "\n",
    "    # 가운데 선의 시작점과 끝점 정의\n",
    "    start_point = (center_x, 4*height//5)          # 하단 중앙\n",
    "    end_point = (center_x, height)       # 중간 지점\n",
    "\n",
    "    # 가운데 선 그리기\n",
    "    result_image = image.copy()\n",
    "    cv2.line(result_image, start_point, end_point, (0, 255, 0), 5)  # 녹색 선\n",
    "\n",
    "    return result_image\n",
    "\n",
    "def find_contours_canny(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "    return image, edges\n",
    "\n",
    "def convert_to_bytes(image):\n",
    "    _, buffer = cv2.imencode('.jpg', image)\n",
    "    return buffer.tobytes()\n",
    "\n",
    "def direction(frame):   #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    height, width, _ = frame.shape\n",
    "    roi_height = int(height / 5)\n",
    "    roi = frame[4 * roi_height: height, :]\n",
    "\n",
    "    result_frame, _ = find_contours_canny(roi)\n",
    "\n",
    "    extended_frame = frame.copy()\n",
    "    extended_frame[4 * roi_height:height, :] = result_frame\n",
    "\n",
    "\n",
    "    # 히스토그램 기반 차선 위치 계산\n",
    "    left_lane, right_lane = histogram_lane_detection(_)\n",
    "\n",
    "    middle_lane = left_lane + (right_lane - left_lane)/2\n",
    "    middle_tank = width / 2\n",
    "    val = middle_tank - middle_lane\n",
    "    #print(val)\n",
    "\n",
    "    if left_lane < 50: #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "        return \"Forward\"\n",
    "    if right_lane > 300: \n",
    "        return \"Forward\"\n",
    "    if np.abs(val) > 100: \n",
    "        return \"Forward\" \n",
    "\n",
    "    tank_threshold = width*0.07\n",
    "    if np.abs(val) < tank_threshold:\n",
    "        #print(\"Forward\")\n",
    "        return \"Forward\"\n",
    "    else:\n",
    "        if val > 0: \n",
    "            #print(\"Left\")\n",
    "            return \"Left\"\n",
    "        else: \n",
    "            #print(\"Right\")\n",
    "            return \"Right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_model_path = \"Misc Files/runs/detect/train/weights/best_v8n.pt\"\n",
    "\n",
    "# YOLO 모델 로드 (YOLOv8)\n",
    "device = torch.device(\"cuda\")\n",
    "model = YOLO(yolo_model_path).to(device = device)\n",
    "\n",
    "# YOLO 예측 및 EfficientNet 적용\n",
    "def run_inference(image, region_name):\n",
    "    \"\"\"\n",
    "    YOLO로 바운딩 박스를 예측하고 각 객체를 EfficientNet으로 분류.\n",
    "    Args:\n",
    "        image_path (str): 입력 이미지 경로\n",
    "    Returns:\n",
    "        list: 예측 결과 (클래스 ID 및 신뢰도)\n",
    "    \"\"\"\n",
    "    # YOLO 예측\n",
    "    results = model.predict(image, save=False, device = device)  #conf=0.3, \n",
    "\n",
    "    # 바운딩 박스 및 클래스 정보\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()  # 클래스 ID\n",
    "\n",
    "    prediction_dict = dict()\n",
    "    prediction_dict[\"region_name\"] = region_name\n",
    "    prediction_dict[\"enemy_tank\"] = 0\n",
    "    prediction_dict[\"ally_tank\"] = 0\n",
    "    prediction_dict[\"enemy_person\"] = 0\n",
    "    prediction_dict[\"ally_person\"] = 0\n",
    "\n",
    "    for predicted_class in class_ids:\n",
    "        if predicted_class == 0:\n",
    "            prediction_dict[\"enemy_tank\"] += 1\n",
    "        elif predicted_class == 1:\n",
    "            prediction_dict[\"ally_tank\"] += 1\n",
    "        elif predicted_class == 2:\n",
    "            prediction_dict[\"enemy_person\"] += 1\n",
    "        elif predicted_class == 3:\n",
    "            prediction_dict[\"ally_person\"] += 1\n",
    "    if prediction_dict[\"enemy_tank\"] != 0:\n",
    "        attack_tank()\n",
    "            \n",
    "    #print(\"enemy_tank\", pred_enemy_tank)\n",
    "    #print(\"ally_tank\", pred_ally_tank)\n",
    "    #print(\"enemy_person\", pred_enemy_person)\n",
    "    #print(\"ally_person\", pred_ally_person)\n",
    "    #print(\"---------------------------------------------------\")\n",
    "    return prediction_dict\n",
    "\n",
    "def attack_tank():\n",
    "    tiki.play_buzzer(500)\n",
    "    time.sleep(1)\n",
    "    tiki.stop_buzzer()\n",
    "    tiki.fire_cannon()\n",
    "    #tiki.log(\"fire tank!\")\n",
    "        \n",
    "\n",
    "def print_log(target_list):\n",
    "    for eval_target in target_list:\n",
    "        log_msg = eval_target[\"region_name\"] + \" AF: \" + str(eval_target[\"ally_person\"]) + \" EF: \" + str(eval_target[\"enemy_person\"])\n",
    "        tiki.log(log_msg)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "def region_evaluate(feed, region_name):\n",
    "    \"\"\"\n",
    "    All image analyses\n",
    "    \"\"\"\n",
    "    prediction_dict = run_inference(feed, region_name)\n",
    "\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3264 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3264 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 120.000005 fps Duration = 8333333 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 5 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 120.000005 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@10.133] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\n",
    "    \"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=640, height=480, framerate=30/1, format=NV12 ! \"\n",
    "    \"nvvidconv flip-method=2 ! video/x-raw, format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink max-buffers=1 drop=True\")\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)  # 가로 해상도 설정\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # 세로 해상도 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wIbo70A6_Tdw"
   },
   "outputs": [],
   "source": [
    "ratio = 3/3  #RATIO MUST BE 2/3 FOR THE BIG CURVEs\n",
    "default_rpm = 30*ratio\n",
    "default_speed = 220*ratio #mm per secondS\n",
    "\n",
    "\n",
    "\n",
    "def forwards(distance):\n",
    "    \"\"\"\n",
    "    Distance units in mm\n",
    "    \"\"\"\n",
    "    duration = distance/default_speed\n",
    "    tiki.forward(default_rpm)\n",
    "    time.sleep(duration)\n",
    "    tiki.stop()\n",
    "\n",
    "def backwards(distance):\n",
    "    \"\"\"\n",
    "    Distance units in mm\n",
    "    \"\"\"\n",
    "    duration = distance/default_speed\n",
    "    tiki.backward(default_rpm)\n",
    "    time.sleep(duration)\n",
    "    tiki.stop()\n",
    "\n",
    "def anticlockwise_turn(radius, delta_angle=90):\n",
    "    \"\"\"\n",
    "    Radius units in mm\n",
    "    \"\"\"\n",
    "    if radius == 0:\n",
    "        tiki.counter_clockwise(default_rpm)\n",
    "        time.sleep((100*3.14*2/default_speed)*(delta_angle/360))\n",
    "        tiki.stop() \n",
    "    else:\n",
    "        forwards(radius)\n",
    "        anticlockwise_turn(0, delta_angle=90)\n",
    "        forwards(radius)\n",
    "\n",
    "def clockwise_turn(radius, delta_angle=90):\n",
    "    \"\"\"\n",
    "    Radius units in mm\n",
    "    \"\"\"\n",
    "    if radius == 0:\n",
    "        tiki.clockwise(default_rpm)\n",
    "        time.sleep((100*3.14*2/default_speed)*(delta_angle/360))   # 110 for 4/3,   96 for 2/3\n",
    "        tiki.stop() \n",
    "    else:\n",
    "        forwards(radius)\n",
    "        anticlockwise_turn(0, delta_angle=90)\n",
    "        forwards(radius)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def follow_line(distance, cap, offset_multiplier = 0.1, custom_ratio = None):\n",
    "    \"\"\"\n",
    "    Distance units in mm\n",
    "    \"\"\"\n",
    "    distance = distance*(60/400)*(110/100)\n",
    "    \n",
    "    if custom_ratio is None:\n",
    "        speed = default_speed\n",
    "        rpm = default_rpm\n",
    "    else:\n",
    "        rpm = 30*custom_ratio\n",
    "        speed = 220*custom_ratio #mm per seconds\n",
    "    \n",
    "    total_duration = distance/speed\n",
    "    subduration = 0.005\n",
    "    offset = rpm*offset_multiplier\n",
    "    instances = int(total_duration/subduration)\n",
    "\n",
    "    for _ in range(instances):\n",
    "        _, feed = cap.read() #@@@@@@@@@@@@@@@@@@@@@@@@@@ EXPERIMENTAL\n",
    "        required_direction = direction(feed)\n",
    "        if required_direction == \"Forward\":\n",
    "            tiki.forward(rpm)\n",
    "        elif required_direction == \"Left\": \n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, rpm-offset)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, rpm+offset)\n",
    "        elif required_direction == \"Right\": \n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, rpm+offset)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, rpm-offset)          \n",
    "        time.sleep(subduration)\n",
    "    tiki.stop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def square_detected(image):\n",
    "    \"\"\"\n",
    "    For the sake of reproducibility, make sure this returns 'True'\n",
    "    only when the center (M00 moment) of the square is within\n",
    "    some fixed distance away from the tank\n",
    "\n",
    "    Also, add a delay such double detections for a single \n",
    "    square doesn't occur\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    roi = image[int(height/2):height, int(width*(0.5-0.2)): int(width*(0.5+0.2)), :]\n",
    "\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([25, 40, 0], dtype=np.uint8)       #loose: [35, 50, 50],   tight: [40, 100, 150]\n",
    "    upper_green = np.array([85, 255, 255], dtype=np.uint8)     #loose: [85, 255, 255], tight: [70, 255, 255]\n",
    "    color_mask = cv2.inRange(hsv_roi, lower_green, upper_green)\n",
    "    masked_roi = cv2.bitwise_and(roi, roi, mask=color_mask)\n",
    "    gray_mask = cv2.cvtColor(masked_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    area_list = [cv2.contourArea(x) for x in contours]\n",
    "    \n",
    "    if not area_list: \n",
    "        #print(\"Green NOT Detected 1\")\n",
    "        return False\n",
    "    \n",
    "    max_area = max(area_list)\n",
    "    if max_area > 500: \n",
    "        #print(\"Green Detected\")\n",
    "        return True #초록색만나면(최대한가깝게 인식하게 area수정)\n",
    "    else:\n",
    "        #print(\"Green NOT Detected 2\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#400/60\n",
    "\n",
    "#clockwise_turn(0, delta_angle=90)\n",
    "#follow_line(500, cap)\n",
    "tiki.log_clear()\n",
    "\"\"\"\n",
    "a = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    a.append(region_evaluate(frame, \"A\")) \n",
    "    print_log(a)\n",
    "    break\n",
    "\"\"\"\n",
    "\n",
    "clockwise_turn(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki.stop()\n",
    "tiki.log_clear()\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "csyB83tPJfuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 enemy_tank, 245.4ms\n",
      "Speed: 22.9ms preprocess, 245.4ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy_tank, 1 enemy_person, 2 ally_persons, 240.8ms\n",
      "Speed: 17.7ms preprocess, 240.8ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy_tank, 2 ally_persons, 247.9ms\n",
      "Speed: 21.9ms preprocess, 247.9ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy_tank, 1 ally_tank, 2 enemy_persons, 212.9ms\n",
      "Speed: 26.9ms preprocess, 212.9ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "crossroad_counter = 1\n",
    "square_counter = 1\n",
    "\n",
    "count_ally_person = []\n",
    "count_enemy_person = []\n",
    "target_list = []\n",
    "\n",
    "square_counter = 1    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "tiki.log_clear()\n",
    "while cap.isOpened():\n",
    "    ret, feed = cap.read()\n",
    "    \n",
    "    if square_detected(feed):\n",
    "        if square_counter == 1:\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            backwards(250+100)\n",
    "            follow_line(100, cap)\n",
    "\n",
    "            anticlockwise_turn(0)\n",
    "            follow_line(400, cap)    #   70\n",
    "            anticlockwise_turn(0)\n",
    "\n",
    "            time.sleep(5)\n",
    "            _, feed1 = cap.read()\n",
    "            region_A = region_evaluate(feed1, \"A\")                   #EVALUATION\n",
    "            target_list.append(region_A)\n",
    "            \n",
    "            anticlockwise_turn(0)\n",
    "            follow_line(460, cap)\n",
    "            \n",
    "            anticlockwise_turn(0)  \n",
    "            follow_line(500, cap)\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            square_counter += 1\n",
    "            continue\n",
    "        elif square_counter == 2:\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            anticlockwise_turn(0, delta_angle = 5+90)   \n",
    "\n",
    "            time.sleep(5)\n",
    "            _, feed2 = cap.read()\n",
    "            region_B = region_evaluate(feed2, \"B\")                     #EVALUATION\n",
    "            target_list.append(region_B)\n",
    "            \n",
    "            clockwise_turn(0, delta_angle = 5+90+10)  \n",
    "            follow_line(1200, cap, offset_multiplier = 0.3, custom_ratio = 2/3)\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            square_counter += 1\n",
    "            continue\n",
    "        elif square_counter == 3:\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            backwards(200+100)\n",
    "            follow_line(100, cap)\n",
    "            \n",
    "            clockwise_turn(0)\n",
    "            follow_line(333, cap)\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            square_counter += 1\n",
    "            continue\n",
    "        elif square_counter == 4:\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            anticlockwise_turn(0, delta_angle = 5+90) \n",
    "\n",
    "            time.sleep(5)\n",
    "            _, feed4 = cap.read()\n",
    "            region_C = region_evaluate(feed4, \"C\")                     #EVALUATION\n",
    "            target_list.append(region_C)\n",
    "            \n",
    "            clockwise_turn(0, delta_angle = 5+90)  \n",
    "            follow_line(333, cap)\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            square_counter += 1\n",
    "            continue\n",
    "        elif square_counter == 5:\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            anticlockwise_turn(0, delta_angle = 5+90)  \n",
    "\n",
    "            time.sleep(5)\n",
    "            _, feed5 = cap.read()\n",
    "            region_D = region_evaluate(feed5, \"D\")                     #EVALUATION\n",
    "            target_list.append(region_D)\n",
    "            \n",
    "            clockwise_turn(0, delta_angle = 5+90)  \n",
    "            \n",
    "            forwards(570) #may need to reduce\n",
    "            anticlockwise_turn(0)\n",
    "            follow_line(267, cap)\n",
    "            #-----------------------------------------------------------------------------------\n",
    "            square_counter += 1\n",
    "            continue\n",
    "#-----------------------------------------------------------------------------------\n",
    "        else:\n",
    "          tiki.stop()\n",
    "          print_log(target_list)\n",
    "          break\n",
    "#-----------------------------------------------------------------------------------\n",
    "    else:\n",
    "        subduration = 0.005\n",
    "        offset = default_rpm*0.2\n",
    "        \n",
    "        required_direction = direction(feed)\n",
    "        if required_direction == \"Forward\":\n",
    "            tiki.forward(default_rpm)\n",
    "        elif required_direction == \"Left\": \n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, default_rpm-offset)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, default_rpm+offset)\n",
    "        elif required_direction == \"Right\": \n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, default_rpm+offset)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, default_rpm-offset)          \n",
    "        time.sleep(subduration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOweM7SuNN5H9q/dLbuxhTW",
   "collapsed_sections": [
    "W6Aig96W9wBW"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
